{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Double-bracket Iteration Scheduling Strategies\n",
    "\n",
    "This notebook presents the different strategies for scheduling the step durations for the double-bracket iteration algorithm and their resepctive accuracies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from qibo import hamiltonians, set_backend\n",
    "from qibo.models.dbi.double_bracket import DoubleBracketGeneratorType, DoubleBracketScheduling, DoubleBracketIteration\n",
    "from qibo.models.dbi.utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Canonical\n",
    "Set up the basic test case with the transverse field ising model hamiltonian and the canonical bracket as the generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hamiltonian\n",
    "set_backend(\"qibojit\", \"numba\")\n",
    "\n",
    "# hamiltonian parameters\n",
    "nqubits = 5\n",
    "h = 3\n",
    "\n",
    "# define the hamiltonian\n",
    "H_TFIM = hamiltonians.TFIM(nqubits=nqubits, h=h)\n",
    "\n",
    "# initialize class\n",
    "dbi = DoubleBracketIteration(deepcopy(H_TFIM),mode=DoubleBracketGeneratorType.canonical)\n",
    "print(\"Initial off diagonal norm\", dbi.off_diagonal_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first generate the relationship between the step duration and the off-diagoanl norm (loss function) for the first step of the iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate data for plotting sigma decrease of the first step\n",
    "s_space = np.linspace(1e-5, 0.6, 100)\n",
    "off_diagonal_norm_diff = []\n",
    "for s in s_space:\n",
    "    dbi_eval = deepcopy(dbi)\n",
    "    dbi_eval(s)\n",
    "    off_diagonal_norm_diff.append(dbi_eval.off_diagonal_norm - dbi.off_diagonal_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default scheduling strategy is grid search: `DoubleBracketScheduling.use_grid_serach`. This strategy specifies a list of step durations to test one by one and finds the one that maximizes the cost function (off-digonal norm of Hamiltonian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_search\n",
    "step_grid = dbi.choose_step(scheduling=DoubleBracketScheduling.use_grid_search)\n",
    "print('grid_search step:', step_grid)\n",
    "# hyperopt\n",
    "step_hyperopt = dbi.choose_step(scheduling=DoubleBracketScheduling.use_hyperopt, max_evals=100, step_max=0.6)\n",
    "print('hyperopt_search step:', step_hyperopt)\n",
    "# polynomial expansion\n",
    "step_poly = dbi.choose_step(scheduling=DoubleBracketScheduling.use_polynomial_approximation, n=5)\n",
    "print('polynomial_approximation step:', step_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results\n",
    "plt.plot(s_space, off_diagonal_norm_diff)\n",
    "plt.axvline(x=step_grid, color='r', linestyle='-',label='grid_search')\n",
    "plt.axvline(x=step_hyperopt, color='g', linestyle='--',label='hyperopt')\n",
    "plt.axvline(x=step_poly, color='m', linestyle='-.',label='polynomial')\n",
    "plt.ylabel(r'$||\\sigma(H_0)||-\\sigma(H_k)||$')\n",
    "plt.xlabel('s')\n",
    "plt.title('hyperopt first step')\n",
    "plt.legend()\n",
    "print('The minimum for cost function in the tested range is:', step_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specified diagonal operator\n",
    "\n",
    "While for the cannonical case, all the scheduling methods are accurate, it is important to realize that the global minimum of the loss function is not always so obvious. It is thus necessary to show whether the 3 converges to an agreeable step duration using different iteration generators, such as the Pauli 'ZZ..Z' operator and 'ZZ..I' operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the digaonal operators\n",
    "Z_op = SymbolicHamiltonian(str_to_symbolic(\"Z\"*nqubits)).dense.matrix\n",
    "ZI_op = SymbolicHamiltonian(str_to_symbolic(\"Z\"*(nqubits-1)+\"I\")).dense.matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbi = DoubleBracketIteration(deepcopy(H_TFIM),mode=DoubleBracketGeneratorType.single_commutator)\n",
    "d = Z_op\n",
    "# generate data for plotting sigma decrease of the first step\n",
    "s_space = np.linspace(1e-5, 0.6, 100)\n",
    "off_diagonal_norm_diff = []\n",
    "for s in s_space:\n",
    "    dbi_eval = deepcopy(dbi)\n",
    "    dbi_eval(s,d=d)\n",
    "    off_diagonal_norm_diff.append(dbi_eval.off_diagonal_norm - dbi.off_diagonal_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_search\n",
    "step_grid = dbi.choose_step(scheduling=DoubleBracketScheduling.use_grid_search, step_max=0.6, d=d)\n",
    "print('grid_search step:', step_grid)\n",
    "# hyperopt\n",
    "step_hyperopt = dbi.choose_step(scheduling=DoubleBracketScheduling.use_hyperopt, d=d, max_evals=100, step_max=0.6)\n",
    "print('hyperopt_search step:', step_hyperopt)\n",
    "# polynomial expansion\n",
    "step_poly = dbi.choose_step(scheduling=DoubleBracketScheduling.use_polynomial_approximation, d=d, n=5)\n",
    "print('polynomial_approximation step:', step_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results\n",
    "plt.plot(s_space, off_diagonal_norm_diff)\n",
    "plt.axvline(x=step_grid, color='r', linestyle='-',label='grid_search')\n",
    "plt.axvline(x=step_hyperopt, color='g', linestyle='--',label='hyperopt')\n",
    "plt.axvline(x=step_poly, color='m', linestyle='-.',label='polynomial')\n",
    "plt.ylabel(r'$||\\sigma(H_0)||-\\sigma(H_k)||$')\n",
    "plt.xlabel('s')\n",
    "plt.title('hyperopt first step')\n",
    "plt.legend()\n",
    "print('The minimum for cost function in the tested range is:', step_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there are two similar \"minimal point\" at 0.03 and 0.22, with the latter being the absolute minimum by an insignificant advantage. However, for practical reasons, we prefer taking the first close-minimum calculated by polynomial approximation. Hence, we can use the polynomial approximation to restrict the search area and obtain better results. For example, we define a search range of 0.1 around the polynomial step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use polynomial expansion as an restriction of hyperopt/grid range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_range = 0.1\n",
    "if step_poly < search_range/2:\n",
    "    step_min = 0\n",
    "    step_max = search_range\n",
    "else:\n",
    "    step_min = step_poly - search_range/2\n",
    "    step_max = step_poly + search_range/2\n",
    "# grid_search\n",
    "step_grid = dbi.choose_step(scheduling=DoubleBracketScheduling.use_grid_search, step_min=step_min, step_max=step_max, d=d)\n",
    "print('grid_search step:', step_grid)\n",
    "# hyperopt\n",
    "step_hyperopt = dbi.choose_step(scheduling=DoubleBracketScheduling.use_hyperopt, step_min=step_min, step_max=step_max, max_evals=100, d=d,)\n",
    "print('hyperopt_search step:', step_hyperopt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results\n",
    "plt.plot(s_space, off_diagonal_norm_diff)\n",
    "plt.axvline(x=step_grid, color='r', linestyle='-',label='grid_search')\n",
    "plt.axvline(x=step_hyperopt, color='g', linestyle='--',label='hyperopt')\n",
    "plt.axvline(x=step_poly, color='m', linestyle='-.',label='polynomial')\n",
    "plt.ylabel(r'$||\\sigma(H_0)||-\\sigma(H_k)||$')\n",
    "plt.xlabel('s')\n",
    "plt.title('hyperopt first step')\n",
    "plt.legend()\n",
    "print('The minimum for cost function in the tested range is:', step_grid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DBF_qibo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
